{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e8l4kv298Fd",
        "outputId": "1cf30965-1f84-4af0-c5fa-f57f99bac0b1"
      },
      "id": "_e8l4kv298Fd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
        "df.drop('smoking_history',axis=1,inplace=True)\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "df = pd.get_dummies(df, columns=categorical_columns)\n",
        "\n",
        "X = df.drop('diabetes', axis=1)\n",
        "y = df['diabetes']\n",
        "\n",
        "oversampler = RandomOverSampler()\n",
        "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "df = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "X = df.drop('diabetes', axis=1)\n",
        "y = df['diabetes']\n"
      ],
      "metadata": {
        "id": "3sPqvUK9Bqgz"
      },
      "id": "3sPqvUK9Bqgz",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "\n",
        "stand = preprocessing.StandardScaler()\n",
        "\n",
        "\n",
        "X = stand.fit_transform(df.drop('diabetes', axis=1).values)\n",
        "y = df['diabetes'].values\n",
        "num_clients = 5\n",
        "\n",
        "def split_data_among_clients(X, y, num_clients=num_clients):\n",
        "    skf = StratifiedKFold(n_splits=num_clients, shuffle=True, random_state=42)\n",
        "    splits = list(skf.split(X, y))\n",
        "\n",
        "    clients_data = [(X[train_idx], y[train_idx]) for train_idx, _ in splits]\n",
        "    return clients_data"
      ],
      "metadata": {
        "id": "TZUrSS20dVRj"
      },
      "id": "TZUrSS20dVRj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scores = {}\n",
        "client_weights = {}\n",
        "\n",
        "# Assume split_data_among_clients function is defined elsewhere\n",
        "clients_data = split_data_among_clients(X, y)\n",
        "\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = (y_pred > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
        "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "def create_model(input_shape):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.0005\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "for i, client_data in enumerate(clients_data):\n",
        "    print(f\"Client {i+1} Data:\")\n",
        "    X_train, y_train = client_data\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Feature scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "    ann = create_model((X_train_scaled.shape[1],))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    scores[f'client_{i+1}'] = {}\n",
        "    client_weights[f'client_{i+1}'] = {}\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    def lr_schedule(epoch):\n",
        "        return learning_rate * (0.1 ** (epoch // 10))\n",
        "\n",
        "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Gradually increase the training data size for each epoch\n",
        "        train_size = int((epoch + 1) / epochs * len(X_train_scaled))\n",
        "        X_train_subset = X_train_scaled[:train_size]\n",
        "        y_train_subset = y_train[:train_size]\n",
        "\n",
        "        history = ann.fit(\n",
        "            X_train_subset, y_train_subset,\n",
        "            epochs=1,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_val_scaled, y_val),\n",
        "            callbacks=[lr_scheduler],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        accuracy, precision, recall, f1 = test_metrics(ann, X_val_scaled, y_val)\n",
        "        scores[f'client_{i+1}'][epoch] = (accuracy, precision, recall, f1)\n",
        "        print(f\"Epoch {epoch+1}: Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "        client_weights[f'client_{i+1}'][epoch] = ann.get_weights()\n",
        "\n",
        "    # Final evaluation on validation set\n",
        "    final_accuracy, final_precision, final_recall, final_f1 = test_metrics(ann, X_val_scaled, y_val)\n",
        "    print(f\"\\nFinal Validation Metrics for Client {i+1}:\")\n",
        "    print(f\"Accuracy: {final_accuracy:.4f}\")\n",
        "    print(f\"Precision: {final_precision:.4f}\")\n",
        "    print(f\"Recall: {final_recall:.4f}\")\n",
        "    print(f\"F1 Score: {final_f1:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g3HtWLHN4-x6",
        "outputId": "03c10c73-277b-4779-acc0-7da298c592ef"
      },
      "id": "g3HtWLHN4-x6",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1 Data:\n",
            "915/915 [==============================] - 2s 2ms/step\n",
            "Epoch 1: Accuracy: 0.8798, Precision: 0.9019, Recall: 0.8521, F1: 0.8763\n",
            "915/915 [==============================] - 2s 2ms/step\n",
            "Epoch 2: Accuracy: 0.8856, Precision: 0.8833, Recall: 0.8884, F1: 0.8858\n",
            "915/915 [==============================] - 1s 2ms/step\n",
            "Epoch 3: Accuracy: 0.8877, Precision: 0.8965, Recall: 0.8764, F1: 0.8863\n",
            "915/915 [==============================] - 3s 3ms/step\n",
            "Epoch 4: Accuracy: 0.8950, Precision: 0.8913, Recall: 0.8996, F1: 0.8954\n",
            "915/915 [==============================] - 1s 2ms/step\n",
            "Epoch 5: Accuracy: 0.8967, Precision: 0.8805, Recall: 0.9177, F1: 0.8987\n",
            "915/915 [==============================] - 1s 2ms/step\n",
            "Epoch 6: Accuracy: 0.9000, Precision: 0.8855, Recall: 0.9187, F1: 0.9018\n",
            "915/915 [==============================] - 1s 2ms/step\n",
            "Epoch 7: Accuracy: 0.9011, Precision: 0.8814, Recall: 0.9268, F1: 0.9035\n",
            "915/915 [==============================] - 1s 2ms/step\n",
            "Epoch 8: Accuracy: 0.9026, Precision: 0.8815, Recall: 0.9299, F1: 0.9051\n",
            "915/915 [==============================] - 3s 3ms/step\n",
            "Epoch 9: Accuracy: 0.9028, Precision: 0.8790, Recall: 0.9341, F1: 0.9057\n",
            "915/915 [==============================] - 1s 2ms/step\n",
            "Epoch 10: Accuracy: 0.9034, Precision: 0.8800, Recall: 0.9340, F1: 0.9062\n",
            "915/915 [==============================] - 1s 2ms/step\n",
            "\n",
            "Final Validation Metrics for Client 1:\n",
            "Accuracy: 0.9034\n",
            "Precision: 0.8800\n",
            "Recall: 0.9340\n",
            "F1 Score: 0.9062\n",
            "\n",
            "Client 2 Data:\n",
            "915/915 [==============================] - 3s 3ms/step\n",
            "Epoch 1: Accuracy: 0.8859, Precision: 0.8835, Recall: 0.8891, F1: 0.8863\n",
            "915/915 [==============================] - 3s 3ms/step\n",
            "Epoch 2: Accuracy: 0.8864, Precision: 0.8906, Recall: 0.8811, F1: 0.8858\n",
            "915/915 [==============================] - 1s 2ms/step\n",
            "Epoch 3: Accuracy: 0.8902, Precision: 0.8896, Recall: 0.8910, F1: 0.8903\n",
            "915/915 [==============================] - 2s 2ms/step\n",
            "Epoch 4: Accuracy: 0.8965, Precision: 0.8886, Recall: 0.9067, F1: 0.8976\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-50737832f670>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0my_train_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         history = ann.fit(\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mX_train_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_subset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scores = {}\n",
        "client_models = {}\n",
        "\n",
        "# Assume split_data_among_clients function is defined elsewhere\n",
        "clients_data = split_data_among_clients(X, y)\n",
        "\n",
        "def test_metrics(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = (y_pred > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
        "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Hyperparameters\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'learning_rate': 0.0005,\n",
        "    'max_depth': 6,\n",
        "    'min_child_weight': 1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'n_estimators': 10\n",
        "}\n",
        "\n",
        "for i, client_data in enumerate(clients_data):\n",
        "    print(f\"Client {i+1} Data:\")\n",
        "    X_train, y_train = client_data\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Feature scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
        "    dval = xgb.DMatrix(X_val_scaled, label=y_val)\n",
        "\n",
        "    client_models[f'client_{i+1}'] = []\n",
        "\n",
        "    for epoch in range(params['n_estimators']):\n",
        "        # Train the model\n",
        "        if epoch == 0:\n",
        "            booster = xgb.train(params, dtrain, num_boost_round=1)\n",
        "        else:\n",
        "            booster = xgb.train(params, dtrain, num_boost_round=1, xgb_model=booster)\n",
        "\n",
        "        client_models[f'client_{i+1}'].append(booster)\n",
        "\n",
        "        accuracy, precision, recall, f1 = test_metrics(booster, dval, y_val)\n",
        "        scores[f'client_{i+1}'] = (accuracy, precision, recall, f1)\n",
        "        print(f\"Epoch {epoch+1}: Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "    # Final evaluation on validation set\n",
        "    final_accuracy, final_precision, final_recall, final_f1 = test_metrics(booster, dval, y_val)\n",
        "    print(f\"\\nFinal Validation Metrics for Client {i+1}:\")\n",
        "    print(f\"Accuracy: {final_accuracy:.4f}\")\n",
        "    print(f\"Precision: {final_precision:.4f}\")\n",
        "    print(f\"Recall: {final_recall:.4f}\")\n",
        "    print(f\"F1 Score: {final_f1:.4f}\\n\")\n",
        "\n",
        "# Aggregation of models (this part can be more sophisticated based on the actual federated learning approach)\n",
        "# This is a simple averaging of model predictions as an example\n",
        "def aggregate_models(client_models, X_test):\n",
        "    predictions = np.zeros((len(X_test), len(client_models)))\n",
        "    for i, client in enumerate(client_models):\n",
        "        for model in client:\n",
        "            dtest = xgb.DMatrix(X_test)\n",
        "            predictions[:, i] += model.predict(dtest)\n",
        "    predictions = predictions / len(client_models)\n",
        "    return predictions.mean(axis=1)\n",
        "\n",
        "# Assume X_test and y_test are defined elsewhere\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "final_predictions = aggregate_models(client_models, X_test_scaled)\n",
        "final_predictions = (final_predictions > 0.5).astype(int)\n",
        "final_accuracy = accuracy_score(y_test, final_predictions)\n",
        "final_precision = precision_score(y_test, final_predictions, zero_division=1)\n",
        "final_recall = recall_score(y_test, final_predictions, zero_division=1)\n",
        "final_f1 = f1_score(y_test, final_predictions, zero_division=1)\n",
        "\n",
        "print(f\"\\nFinal Aggregated Metrics:\")\n",
        "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
        "print(f\"Precision: {final_precision:.4f}\")\n",
        "print(f\"Recall: {final_recall:.4f}\")\n",
        "print(f\"F1 Score: {final_f1:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mbNAKbnAalCA",
        "outputId": "88a06026-0352-4f20-df4e-e17a1fd70d25"
      },
      "id": "mbNAKbnAalCA",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1 Data:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Accuracy: 0.7984, Precision: 0.7125, Recall: 1.0000, F1: 0.8321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Accuracy: 0.8858, Precision: 0.8771, Recall: 0.8972, F1: 0.8870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Accuracy: 0.8858, Precision: 0.8771, Recall: 0.8972, F1: 0.8870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Accuracy: 0.8858, Precision: 0.8771, Recall: 0.8972, F1: 0.8870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Accuracy: 0.8878, Precision: 0.8870, Recall: 0.8885, F1: 0.8878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Accuracy: 0.8887, Precision: 0.8912, Recall: 0.8853, F1: 0.8882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Accuracy: 0.8887, Precision: 0.8912, Recall: 0.8853, F1: 0.8882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Accuracy: 0.8887, Precision: 0.8912, Recall: 0.8853, F1: 0.8882\n",
            "Epoch 9: Accuracy: 0.8887, Precision: 0.8912, Recall: 0.8853, F1: 0.8882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Accuracy: 0.8887, Precision: 0.8912, Recall: 0.8853, F1: 0.8882\n",
            "\n",
            "Final Validation Metrics for Client 1:\n",
            "Accuracy: 0.8887\n",
            "Precision: 0.8912\n",
            "Recall: 0.8853\n",
            "F1 Score: 0.8882\n",
            "\n",
            "Client 2 Data:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n",
            "Epoch 3: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n",
            "Epoch 8: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n",
            "Epoch 9: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Accuracy: 0.8854, Precision: 0.8795, Recall: 0.8932, F1: 0.8863\n",
            "\n",
            "Final Validation Metrics for Client 2:\n",
            "Accuracy: 0.8854\n",
            "Precision: 0.8795\n",
            "Recall: 0.8932\n",
            "F1 Score: 0.8863\n",
            "\n",
            "Client 3 Data:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Accuracy: 0.4983, Precision: 0.4983, Recall: 1.0000, F1: 0.6651\n",
            "Epoch 2: Accuracy: 0.7958, Precision: 0.7093, Recall: 1.0000, F1: 0.8299\n",
            "Epoch 3: Accuracy: 0.7958, Precision: 0.7093, Recall: 1.0000, F1: 0.8299\n",
            "Epoch 4: Accuracy: 0.8829, Precision: 0.8738, Recall: 0.8942, F1: 0.8839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Accuracy: 0.8829, Precision: 0.8738, Recall: 0.8942, F1: 0.8839\n",
            "Epoch 6: Accuracy: 0.8829, Precision: 0.8738, Recall: 0.8942, F1: 0.8839\n",
            "Epoch 7: Accuracy: 0.8829, Precision: 0.8738, Recall: 0.8942, F1: 0.8839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Accuracy: 0.8829, Precision: 0.8738, Recall: 0.8942, F1: 0.8839\n",
            "Epoch 9: Accuracy: 0.8829, Precision: 0.8738, Recall: 0.8942, F1: 0.8839\n",
            "Epoch 10: Accuracy: 0.8829, Precision: 0.8738, Recall: 0.8942, F1: 0.8839\n",
            "\n",
            "Final Validation Metrics for Client 3:\n",
            "Accuracy: 0.8829\n",
            "Precision: 0.8738\n",
            "Recall: 0.8942\n",
            "F1 Score: 0.8839\n",
            "\n",
            "Client 4 Data:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Accuracy: 0.4973, Precision: 0.4973, Recall: 1.0000, F1: 0.6643\n",
            "Epoch 2: Accuracy: 0.4973, Precision: 0.4973, Recall: 1.0000, F1: 0.6643\n",
            "Epoch 3: Accuracy: 0.7941, Precision: 0.7072, Recall: 1.0000, F1: 0.8285\n",
            "Epoch 4: Accuracy: 0.7941, Precision: 0.7072, Recall: 1.0000, F1: 0.8285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Accuracy: 0.7941, Precision: 0.7072, Recall: 1.0000, F1: 0.8285\n",
            "Epoch 6: Accuracy: 0.8809, Precision: 0.8676, Recall: 0.8976, F1: 0.8823\n",
            "Epoch 7: Accuracy: 0.8809, Precision: 0.8676, Recall: 0.8976, F1: 0.8823\n",
            "Epoch 8: Accuracy: 0.8817, Precision: 0.8700, Recall: 0.8960, F1: 0.8828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Accuracy: 0.8817, Precision: 0.8700, Recall: 0.8960, F1: 0.8828\n",
            "Epoch 10: Accuracy: 0.8821, Precision: 0.8710, Recall: 0.8956, F1: 0.8831\n",
            "\n",
            "Final Validation Metrics for Client 4:\n",
            "Accuracy: 0.8821\n",
            "Precision: 0.8710\n",
            "Recall: 0.8956\n",
            "F1 Score: 0.8831\n",
            "\n",
            "Client 5 Data:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Accuracy: 0.4986, Precision: 0.4986, Recall: 1.0000, F1: 0.6654\n",
            "Epoch 2: Accuracy: 0.7974, Precision: 0.7111, Recall: 1.0000, F1: 0.8311\n",
            "Epoch 3: Accuracy: 0.7974, Precision: 0.7111, Recall: 1.0000, F1: 0.8311\n",
            "Epoch 4: Accuracy: 0.8848, Precision: 0.8776, Recall: 0.8937, F1: 0.8856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Accuracy: 0.8848, Precision: 0.8776, Recall: 0.8937, F1: 0.8856\n",
            "Epoch 6: Accuracy: 0.8848, Precision: 0.8776, Recall: 0.8937, F1: 0.8856\n",
            "Epoch 7: Accuracy: 0.8848, Precision: 0.8776, Recall: 0.8937, F1: 0.8856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:19:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"n_estimators\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Accuracy: 0.8848, Precision: 0.8776, Recall: 0.8937, F1: 0.8856\n",
            "Epoch 9: Accuracy: 0.8848, Precision: 0.8776, Recall: 0.8937, F1: 0.8856\n",
            "Epoch 10: Accuracy: 0.8848, Precision: 0.8776, Recall: 0.8937, F1: 0.8856\n",
            "\n",
            "Final Validation Metrics for Client 5:\n",
            "Accuracy: 0.8848\n",
            "Precision: 0.8776\n",
            "Recall: 0.8937\n",
            "F1 Score: 0.8856\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_test' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9fddebb074c6>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Assume X_test and y_test are defined elsewhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mfinal_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mfinal_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_predictions\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 246.644046,
      "end_time": "2023-05-22T11:35:19.197572",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-05-22T11:31:12.553526",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}